%% MICRO50

@inproceedings{li2017drisa,
  title={DRISA: A DRAM-based Reconfigurable In-Situ Accelerator},
  author={Li, Shuangchen and Niu, Dimin and Malladi, Krishna T and Zheng, Hongzhong and Brennan, Bob and Xie, Yuan},
  booktitle={Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture},
  pages={288--301},
  year={2017},
  organization={ACM}
}

@inproceedings{park2017scaleout,
  title={Scale-out acceleration for machine learning},
  author={Park, Jongse and Sharma, Hardik and Mahajan, Divya and Kim, Joon Kyung and Olds, Preston and Esmaeilzadeh, Hadi},
  booktitle={Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture},
  pages={367--381},
  year={2017},
  organization={ACM}
}

@inproceedings{hill2017deftnn,
  title={DeftNN: addressing bottlenecks for DNN execution on GPUs via synapse vector elimination and near-compute data fission},
  author={Hill, Parker and Jain, Animesh and Hill, Mason and Zamirai, Babak and Hsu, Chang-Hong and Laurenzano, Michael A and Mahlke, Scott and Tang, Lingjia and Mars, Jason},
  booktitle={Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture},
  pages={786--799},
  year={2017},
  organization={ACM}
}

%% MICRO49

@inproceedings{caulfield2016cloudscale,
  title={A cloud-scale acceleration architecture},
  author={Caulfield, Adrian M and Chung, Eric S and Putnam, Andrew and Angepat, Hari and Fowers, Jeremy and Haselman, Michael and Heil, Stephen and Humphrey, Matt and Kaur, Puneet and Kim, Joo-Young and others},
  booktitle={Microarchitecture (MICRO), 2016 49th Annual IEEE/ACM International Symposium on},
  pages={1--13},
  year={2016},
  organization={IEEE}
}

%% ASPLOS 2017

@inproceedings{gao2017tetris,
  title={TETRIS: Scalable and Efficient Neural Network Acceleration with 3D Memory},
  author={Gao, Mingyu and Pu, Jing and Yang, Xuan and Horowitz, Mark and Kozyrakis, Christos},
  booktitle={Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages={751--764},
  year={2017},
  organization={ACM}
}

@inproceedings{rajbhandari2017optimizing,
  title={Optimizing CNNs on Multicores for Scalability, Performance and Goodput},
  author={Rajbhandari, Samyam and He, Yuxiong and Ruwase, Olatunji and Carbin, Michael and Chilimbi, Trishul},
  booktitle={Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages={267--280},
  year={2017},
  organization={ACM}
}

%% ISCA 2016

@inproceedings{albericio2016cnvlutin, 
author={J. Albericio and P. Judd and T. Hetherington and T. Aamodt and N. E. Jerger and A. Moshovos}, 
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
title={Cnvlutin: Ineffectual-Neuron-Free Deep Neural Network Computing}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-13}, 
keywords={decision making;memory architecture;neural nets;parallel architectures;performance evaluation;power aware computing;Cnvlutin;DNN;ED2P;EDP;computation elimination decisions;data parallel units;data storage format;data storage format encoding;data-parallel architecture;energy delay product;energy delay squared product;energy efficiency;hardware acceleration;hierarchical data-parallel units;image classification;ineffectual-neuron-free deep neural network computing;memory hierarchy;value-based approach;zero-valued operand multiplications;Acceleration;Computer architecture;Delays;Feature extraction;Hardware;Neural networks;Neurons}, 
doi={10.1109/ISCA.2016.11}, 
ISSN={1063-6897}, 
month={June},}

@inproceedings{shafiee2016isaac, 
author={A. Shafiee and A. Nag and N. Muralimanohar and R. Balasubramonian and J. P. Strachan and M. Hu and R. S. Williams and V. Srikumar}, 
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
title={ISAAC: A Convolutional Neural Network Accelerator with In-Situ Analog Arithmetic in Crossbars}, 
year={2016}, 
volume={}, 
number={}, 
pages={14-26}, 
keywords={DRAM chips;digital arithmetic;learning (artificial intelligence);memristor circuits;neural nets;ADC;DaDianNao architecture;ISAAC architecture;analog-to-digital conversion;convolutional neural network accelerator;data encoding;digital arithmetic operations;dot-product operations;eDRAM banks;in-situ analog arithmetic crossbars;in-situ processing approach;machine learning algorithms;memristor crossbar arrays;memristor storage;pipelined architecture design;Biological neural networks;Computer architecture;Kernel;Machine learning algorithms;Memristors;Neurons;Pipelines;CNN;DNN;accelerator;analog;memristor;neural}, 
doi={10.1109/ISCA.2016.12}, 
ISSN={1063-6897}, 
month={June},}

@inproceedings{han2016eie, 
author={S. Han and X. Liu and H. Mao and J. Pu and A. Pedram and M. A. Horowitz and W. J. Dally}, 
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
title={EIE: Efficient Inference Engine on Compressed Deep Neural Network}, 
year={2016}, 
volume={}, 
number={}, 
pages={243-254}, 
keywords={DRAM chips;SRAM chips;matrix multiplication;neural nets;sparse matrices;AlexNet;DNN;DRAM;EIE;VGGNet;compressed deep neural network;embedded system;energy efficient inference engine;onchip SRAM;power dissipation;sparse matrix-vector multiplication;weight sharing;Acceleration;Computational modeling;Hardware;Neural networks;Random access memory;Sparse matrices;System-on-chip;ASIC;Algorithm-Hardware co-Design;Deep Learning;Hardware Acceleration;Model Compression}, 
doi={10.1109/ISCA.2016.30}, 
ISSN={1063-6897}, 
month={June},}

@inproceedings{likamwa2016redeye, 
author={R. LiKamWa and Y. Hou and Y. Gao and M. Polansky and L. Zhong}, 
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
title={RedEye: Analog ConvNet Image Sensor Architecture for Continuous Mobile Vision}, 
year={2016}, 
volume={}, 
number={}, 
pages={255-266}, 
keywords={computer vision;image sensors;neural nets;quantisation (signal);ConvNet image sensor architecture;RedEye;algorithmic cyclic reuse;analog domain;analog readout circuitry;cloudlet-based system energy reduction;column-parallel design;computation-based system energy reduction;continuous mobile vision;convolutional neural network;data traffic;image frame capturing;intensive computation;physical design reuse;programmable mechanisms;quantization processing;sensor energy reduction;vision feature processing;vision processing;Analog circuits;Arrays;Complexity theory;Convolution;Image sensors;Mobile communication;Neurons;computer vision;continuous mobile vision;pre-quantization processing;programmable analog computing}, 
doi={10.1109/ISCA.2016.31}, 
ISSN={1063-6897}, 
month={June},}

@inproceedings{reagen2016minerva, 
author={B. Reagen and P. Whatmough and R. Adolf and S. Rama and H. Lee and S. K. Lee and J. M. Hern√°ndez-Lobato and G. Y. Wei and D. Brooks}, 
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
title={Minerva: Enabling Low-Power, Highly-Accurate Deep Neural Network Accelerators}, 
year={2016}, 
volume={}, 
number={}, 
pages={267-278}, 
keywords={neural nets;DNN hardware accelerators;DNN model accuracy;Minerva;SRAM voltages;active hardware fault detection;automated codesign;classification tasks;deep neural network accelerators;deep neural networks;domain-aware error mitigation;fixed-point accelerator baseline;general-purpose hardware;heterogeneous datatype optimization;inline predication;magnitude improvement;mobile devices;power-constrained IoT;small activity values;specialized hardware;ultra-low power DNN accelerators;Circuit faults;Hardware;Integrated circuit modeling;Libraries;Optimization;Random access memory;Space exploration}, 
doi={10.1109/ISCA.2016.32}, 
ISSN={1063-6897}, 
month={June},}

@inproceedings{chen2016eyeriss, 
author={Y. H. Chen and J. Emer and V. Sze}, 
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
title={Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks}, 
year={2016}, 
volume={}, 
number={}, 
pages={367-379}, 
keywords={computer architecture;convolution;data flow computing;neural nets;power aware computing;AlexNet CNN configurations;Eyeriss;PE local storage;RS dataflow;computational complexity;data movement energy consumption minimization;deep CNNs;deep convolutional neural networks;direct interPE communication;energy-efficient CNN processing;energy-efficient dataflow;feature map pixels;high-dimensional convolutions;local data reuse;parallel processing;partial sum accumulations;processing engine local storage;row-stationary dataflow;spatial architecture;spatial parallelism;Arrays;Parallel processing;Radio frequency;Random access memory;Shape;Throughput;Convolutional Neural Networks;Dataflow;Energy Efficiency;Spatial Architecture}, 
doi={10.1109/ISCA.2016.40}, 
ISSN={1063-6897}, 
month={June},}

@inproceedings{kim2016neurocube, 
author={D. Kim and J. Kung and S. Chai and S. Yalamanchili and S. Mukhopadhyay}, 
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
title={Neurocube: A Programmable Digital Neuromorphic Architecture with High-Density 3D Memory}, 
year={2016}, 
volume={}, 
number={}, 
pages={380-392}, 
keywords={logic circuits;memory architecture;neural nets;storage management chips;HMC;Neurocube;convolutional neural network;high-density 3D memory;logic tier;memory centric computing;neural computing;programmable digital neuromorphic architecture;Artificial neural networks;Biological neural networks;Computer architecture;Neurons;Random access memory;Three-dimensional displays;Neural nets;Neurocomputers;Neuromorphic computing}, 
doi={10.1109/ISCA.2016.41}, 
ISSN={1063-6897}, 
month={June},}

@inproceedings{liu2016cambricon, 
author={S. Liu and Z. Du and J. Tao and D. Han and T. Luo and Y. Xie and Y. Chen and T. Chen}, 
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
title={Cambricon: An Instruction Set Architecture for Neural Networks}, 
year={2016}, 
volume={}, 
number={}, 
pages={393-405}, 
keywords={instruction sets;neural net architecture;power aware computing;Cambricon;NN high-level functional blocks;TSMC 65nm technology;application-specific hardware accelerators;control instructions;data transfer instructions;domain-specific ISA;domain-specific instruction set architecture;energy-efficiency;general-purpose processors;load-store architecture;logical instructions;matrix instructions;neural networks;scalar instructions;vector instructions;Artificial neural networks;Computer architecture;Data transfer;Ground penetrating radar;Libraries;Registers;System-on-chip}, 
doi={10.1109/ISCA.2016.42}, 
ISSN={1063-6897}, 
month={June},}

%% ISCA 2015

@INPROCEEDINGS{hauswald2015djinnandtonic, 
author={J. Hauswald and Y. Kang and M. A. Laurenzano and Q. Chen and C. Li and T. Mudge and R. G. Dreslinski and J. Mars and L. Tang}, 
booktitle={2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)}, 
title={DjiNN and Tonic: DNN as a service and its implications for future warehouse scale computers}, 
year={2015}, 
volume={}, 
number={}, 
pages={27-40}, 
keywords={graphics processing units;learning (artificial intelligence);neural nets;DjiNN;NVIDIA K40 GPU;Tonic suite;WSC architectures;deep neural networks;homogeneous integrated GPU servers;machine learning;warehouse scale computers;Face;Graphics processing units;Libraries;Neural networks;Neurons;Servers;Throughput}, 
doi={10.1145/2749469.2749472}, 
ISSN={1063-6897}, 
month={June},}

@inproceedings{du2015shidiannao, 
    author={Z. Du and R. Fasthuber and T. Chen and P. Ienne and L. Li and T. Luo and X. Feng and Y. Chen and O. Temam}, 
    booktitle={ISCA},
    title={ShiDianNao: Shifting vision processing closer to the sensor}, 
    year={2015}, 
    month={June},
}

%% ISCA 2014

@inproceedings{putnam2014reconfigurable,
  title={A reconfigurable fabric for accelerating large-scale datacenter services},
  author={Putnam, Andrew and Caulfield, Adrian M and Chung, Eric S and Chiou, Derek and Constantinides, Kypros and Demme, John and Esmaeilzadeh, Hadi and Fowers, Jeremy and Gopal, Gopi Prashanth and Gray, Jan and others},
  booktitle={Computer Architecture (ISCA), 2014 ACM/IEEE 41st International Symposium on},
  pages={13--24},
  year={2014},
  organization={IEEE}
}

%% FPGA 2015

@inproceedings{zhang2015optimizing,
  title={Optimizing fpga-based accelerator design for deep convolutional neural networks},
  author={Zhang, Chen and Li, Peng and Sun, Guangyu and Guan, Yijin and Xiao, Bingjun and Cong, Jason},
  booktitle={Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
  pages={161--170},
  year={2015},
  organization={ACM}
}

%% Other

@article{ovtcharov2015accelerating,
  title={Accelerating deep convolutional neural networks using specialized hardware},
  author={Ovtcharov, Kalin and Ruwase, Olatunji and Kim, Joo-Young and Fowers, Jeremy and Strauss, Karin and Chung, Eric S},
  journal={Microsoft Research Whitepaper},
  volume={2},
  number={11},
  year={2015}
}

@inproceedings{lee2009convolutional,
  title={Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations},
  author={Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y},
  booktitle={ICML},
  year={2009},
  organization={ACM}
}

@misc{karpathy2015cs231n, 
  title={CS231n Convolutional Neural Networks for Visual Recognition},
  author={Karpathy, Andrej},
  year={2015},
  url="\url{http://cs231n.github.io/convolutional-networks/}",
}

@inproceedings{vanhoucke2011improving,
  title={Improving the speed of neural networks on CPUs},
  author={Vanhoucke, Vincent and Senior, Andrew and Mao, Mark Z},
  booktitle={Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop},
  volume={1},
  pages={4},
  year={2011}
}

% HTM Hardware Accelerators

@inproceedings{walter2017spinnaker,
    author={F. Walter and M. Sandner and F. Rc√∂hrbein and A. Knoll}, 
    booktitle={ISCAS},
    title={Towards a neuromorphic implementation of hierarchical temporal memory on SpiNNaker}, 
    year={2017}, 
    month={May},
}

@inproceedings{gabrielsson2012hierarchical, 
    author={P. Gabrielsson and R. K√∂nig and U. Johansson}, 
    booktitle={CIFEr}, 
    title={Hierarchical Temporal Memory-based algorithmic trading of financial markets}, 
    year={2012}, 
    month={March},
}

@article{sinkevicius2011monitoring,
  title={Monitoring of humans traffic using hierarchical temporal memory algorithms},
  author={Sinkevicius, S and Simutis, R and Raudonis, V},
  journal={Elektronika ir Elektrotechnika},
  volume={115},
  number={9},
  pages={91--96},
  year={2011}
}

@inproceedings{zhituo2012content,
  title={A Content-Based Image Retrieval System Using Multiple Hierarchical Temporal Memory Classifiers},
  author={Zhituo, Xia and Hao, Ruan and Hao, Wang},
  booktitle={ISCID},
  volume={2},
  pages={438--441},
  year={2012},
  organization={IEEE}
}

@article{bobier2007handwritten,
  title={Handwritten digit recognition using hierarchical temporal memory},
  author={Bobier, Bruce},
  journal={University of Guelph},
  year={2007}
}

% CONVs take 90% of cycles in CNN

%% Yangqing's Dissertation

@book{jia2014learning,
  title={Learning semantic image representations at a large scale},
  author={Jia, Yangqing},
  year={2014},
  publisher={University of California, Berkeley}
}

@inproceedings{ren2015vectorization,
  title={On Vectorization of Deep Convolutional Neural Networks for Vision Tasks.},
  author={Ren, Jimmy SJ and Xu, Li},
  booktitle={AAAI},
  pages={1840--1846},
  year={2015}
}

% Other

@article{fridman2017autonomous,
  title={MIT Autonomous Vehicle Technology Study: Large-Scale Deep Learning Based Analysis of Driver Behavior and Interaction with Automation},
  author={Fridman, Lex and Brown, Daniel E and Glazer, Michael and Angell, William and Dodd, Spencer and Jenik, Benedikt and Terwilliger, Jack and Kindelsberger, Julia and Ding, Li and Seaman, Sean and others},
  journal={arXiv preprint arXiv:1711.06976},
  year={2017}
}

@article{laughlin2003communication,
  title={Communication in neuronal networks},
  author={Laughlin, Simon B and Sejnowski, Terrence J},
  journal={Science},
  volume={301},
  number={5641},
  pages={1870--1874},
  year={2003},
  publisher={American Association for the Advancement of Science}
}

@techreport{rosenblatt_principles_1961,
	title = {Principles of neurodynamics. perceptrons and the theory of brain mechanisms},
	institution = {CORNELL AERONAUTICAL LAB INC BUFFALO NY},
	author = {Rosenblatt, Frank},
	year = {1961},
	keywords = {multilayer perceptrons}
}

@inproceedings{dhawan2012fathom,
  title={Fathom: A browser-based network measurement platform},
  author={Dhawan, Mohan and Samuel, Justin and Teixeira, Renata and Kreibich, Christian and Allman, Mark and Weaver, Nicholas and Paxson, Vern},
  booktitle={Proceedings of the 2012 ACM conference on Internet measurement conference},
  pages={73--86},
  year={2012},
  organization={ACM}
}

@article{dlugosch2014efficient,
  title={An efficient and scalable semiconductor architecture for parallel automata processing},
  author={Dlugosch, Paul and Brown, Dave and Glendenning, Paul and Leventhal, Michael and Noyes, Harold},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={25},
  number={12},
  pages={3088--3098},
  year={2014},
  publisher={IEEE}
}

@techreport{rosenblatt1961principles,
  title={Principles of neurodynamics. perceptrons and the theory of brain mechanisms},
  author={Rosenblatt, Frank},
  year={1961},
  institution={CORNELL AERONAUTICAL LAB INC BUFFALO NY}
}

@article{ahmad2015properties,
  title={Properties of sparse distributed representations and their application to hierarchical temporal memory},
  author={Ahmad, Subutai and Hawkins, Jeff},
  journal={arXiv preprint arXiv:1503.07469},
  year={2015}
}

@article{mnatzaganian2017mathematical,
  title={A mathematical formalization of hierarchical temporal memory‚Äôs spatial pooler},
  author={Mnatzaganian, James and Fokou{\'e}, Ernest and Kudithipudi, Dhireesha},
  journal={Frontiers in Robotics and AI},
  volume={3},
  pages={81},
  year={2017},
  publisher={Frontiers}
}

@article{mcculloch1943logical,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  number={4},
  pages={115--133},
  year={1943},
  publisher={Springer}
}

@book{hebb2005organization,
  title={The organization of behavior: A neuropsychological theory},
  author={Hebb, Donald Olding},
  year={2005},
  publisher={Psychology Press}
}

@article{farley1954simulation,
  title={Simulation of self-organizing systems by digital computer},
  author={Farley, BWAC and Clark, W},
  journal={Transactions of the IRE Professional Group on Information Theory},
  volume={4},
  number={4},
  pages={76--84},
  year={1954},
  publisher={IEEE}
}

@article{rochester1956tests,
  title={Tests on a cell assembly theory of the action of the brain, using a large digital computer},
  author={Rochester, Nathaniel and Holland, J and Haibt, L and Duda, W},
  journal={IRE Transactions on information Theory},
  volume={2},
  number={3},
  pages={80--93},
  year={1956},
  publisher={IEEE}
}